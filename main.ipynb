{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4d5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "data_dir = \"/home/shared/datasets/evimo/train\"\n",
    "\n",
    "#save_dir =  '/home/shared/datasets/even_bdd/426x240/oms/'\n",
    "#save_dir = os.path.join(os.getcwd(), 'results/')\n",
    "save_dir = os.path.join(os.getcwd(), 'results/')\n",
    "\n",
    "from oms.evimo_dataset import EVIMODataset\n",
    "from oms.mod_dataset import MODDataset\n",
    "from oms.main import generate_oms\n",
    "from oms.filter_construction import *\n",
    "from oms.bin.activation_functions.activation_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3277fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EVIMO dataset from .npz files, or from .npy files if already converted\n",
      "Already converted all files to .npy\n",
      "Loading EVIMO dataset from .npz files, or from .npy files if already converted\n",
      "Already converted all files to .npy\n",
      "Loading EVIMO dataset from .npz files, or from .npy files if already converted\n",
      "Already converted all files to .npy\n",
      "Loading EVIMO dataset from .npz files, or from .npy files if already converted\n",
      "Already converted all files to .npy\n",
      "Loading EVIMO dataset from .npz files, or from .npy files if already converted\n",
      "Already converted all files to .npy\n",
      "Loading EVIMO dataset from .npz files, or from .npy files if already converted\n",
      "Already converted all files to .npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing OMS frames:   0%|                                                                                                                                                                                                                          | 0/41 [00:00<?, ?it/s]/home/mavi/eccv_suplementary/oms/bin/oms_fixed_kernels/oms.py:80: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /opt/conda/conda-bld/pytorch_1682343964576/work/aten/src/ATen/native/Convolution.cpp:1003.)\n",
      "  convolved = F.conv2d(x, kernel, stride=stride, padding='same')\n",
      "Computing OMS frames: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 349.27it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 383.79it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:00<00:00, 383.69it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 197/197 [00:00<00:00, 383.66it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 253/253 [00:00<00:00, 383.91it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 539/539 [00:01<00:00, 381.65it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:00<00:00, 384.00it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 236/236 [00:00<00:00, 385.38it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 129/129 [00:00<00:00, 376.98it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 773/773 [00:02<00:00, 374.05it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 262/262 [00:00<00:00, 384.60it/s]\n",
      "Computing OMS frames: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:00<00:00, 377.39it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 383.28it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 159/159 [00:00<00:00, 381.94it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 555/555 [00:01<00:00, 377.07it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:00<00:00, 384.56it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 109/109 [00:00<00:00, 392.67it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 435/435 [00:01<00:00, 383.05it/s]\n",
      "Computing OMS frames: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 181/181 [00:00<00:00, 364.06it/s]\n",
      "Computing OMS frames: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1594/1594 [00:04<00:00, 376.91it/s]\n",
      "Computing OMS frames: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1402/1402 [00:03<00:00, 378.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM average: 0.7978463984375624\n",
      "spike_rate: 13.034332741957275 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "center_kernel_radius = 2\n",
    "surround_kernel_radius = 4\n",
    "oms_threshold = .96\n",
    "\n",
    "kernel = {\n",
    "    \"filter\": gaussian_filter,\n",
    "    \"activation_function\": neuro_activation_function, \n",
    "    \"stride\": 1,\n",
    "    \"threshold\":oms_threshold,\n",
    "    \"r_c\": center_kernel_radius,\n",
    "    \"r_s\": surround_kernel_radius,\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "--TODO--\n",
    "--MODIFY THE PATH TO THE EV-IMO DATASET--\n",
    "\"\"\"\n",
    "data_dir = \"/home/shared/datasets/evimo/eval\"\n",
    "dataset = EVIMODataset(data_dir)\n",
    "save_dir = os.path.join(os.getcwd(), 'eval_evimo/')\n",
    "generate_oms(dataset, kernel,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930f17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing OMS frames: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4999/4999 [00:13<00:00, 369.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM average: 0.8175266234016173\n",
      "spike_rate: 13.336583868574515 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "center_kernel_radius = 2\n",
    "surround_kernel_radius = 4\n",
    "oms_threshold = .5\n",
    "\n",
    "kernel = {\n",
    "    \"filter\": gaussian_filter,\n",
    "    \"activation_function\": neuro_activation_function, \n",
    "    \"stride\": 1,\n",
    "    \"threshold\":oms_threshold,\n",
    "    \"r_c\": center_kernel_radius,\n",
    "    \"r_s\": surround_kernel_radius,\n",
    "}\n",
    "\"\"\"\n",
    "--TODO--\n",
    "--MODIFY THE PATH TO THE EV-IMO DATASET--\n",
    "\"\"\"\n",
    "data_dir = \"/home/shared/MOD\"\n",
    "dataset = MODDataset(data_dir)\n",
    "save_dir = os.path.join(os.getcwd(), 'eval_mod/')\n",
    "generate_oms(dataset, kernel,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c1af12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mavi/eccv_suplementary/logs/20240314-150457\n",
      "MOD used\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from runner import Runner\n",
    "\n",
    "from config.utils import getTestConfigs\n",
    "\n",
    "configs = getTestConfigs(os.path.join(os.getcwd(), 'logs'), os.path.join(os.getcwd(), 'general_config.yaml'))\n",
    "\n",
    "# TODO\n",
    "# Either 'EVIMO' or 'MOD' to test each dataset\n",
    "dataset_type = \"MOD\"\n",
    "# TODO\n",
    "# Change to test with different validation sequences\n",
    "masks_path= \"/home/shared/MOD/\"\n",
    "config_file = os.path.join(os.getcwd(), 'general_config.yaml')\n",
    "# TODO\n",
    "# Change path to the directory where the OMS masks are saved\n",
    "oms_path = os.path.join(os.getcwd(), 'eval_mod')\n",
    "#masks_path = \"/home/shared/datasets/\"\n",
    "runner = Runner(oms_datadir = oms_path,\n",
    "                masks_datadir = masks_path,\n",
    "                crop=False, \n",
    "                maxBackgroundRatio=1.5, \n",
    "                datasetType=dataset_type, \n",
    "                checkpoint='/', #no model for checkpoint\n",
    "                modeltype='', # no model type required\n",
    "                log_config=configs['log'],\n",
    "                general_config=config_file,\n",
    "                maskDir='',  #masks are in the same directory as frames\n",
    "                incrementalPercent = 1,\n",
    "                saveImages= False, #code not prepared for image generation\n",
    "                saveImageInterval=1, \n",
    "                imageDir=\"\")\n",
    "runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Either 'EVIMO' or 'MOD' to test each dataset\n",
    "dataset_type = \"EVIMO\"\n",
    "# TODO\n",
    "# Change to test with different validation sequences\n",
    "masks_path= \"/home/shared/datasets/evimo/eval/wall/txt/seq_00\"\n",
    "config_file = os.path.join(os.getcwd(), 'general_config.yaml')\n",
    "oms_path = os.path.join(os.getcwd(), 'eval_evimo')\n",
    "# TODO\n",
    "# Change to test with different validation sequences\n",
    "oms_path += \"/wall/seq_00\"\n",
    "#masks_path = \"/home/shared/datasets/\"\n",
    "runner = Runner(oms_datadir = oms_path,\n",
    "                masks_datadir = masks_path,\n",
    "                crop=False, \n",
    "                maxBackgroundRatio=1.5, \n",
    "                datasetType=dataset_type, \n",
    "                checkpoint='/', #no model for checkpoint\n",
    "                modeltype='', # no model type required\n",
    "                log_config=configs['log'],\n",
    "                general_config=config_file,\n",
    "                maskDir='', \n",
    "                incrementalPercent = 1,\n",
    "                saveImages= False, \n",
    "                saveImageInterval=1, \n",
    "                imageDir=\"\")\n",
    "runner.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
