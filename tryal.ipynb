{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b8296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datasets.evimo_dataset import EVIMODataset\n",
    "import dataloader.base as base\n",
    "\n",
    "from utils.masks_to_boxes import masks_to_boxes, detection_rate\n",
    "from utils.gpu import moveToGPUDevice\n",
    "from utils.rbase import RBase\n",
    "\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch.nn as nn \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51999274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    batch = list(filter (lambda x:x is not None, batch))\n",
    "    if not batch:\n",
    "        return None\n",
    "\n",
    "    return default_collate(batch)\n",
    "\n",
    "class Runner(RBase):\n",
    "\n",
    "    def __init__(self, crop, maxBackgroundRatio, datasetType, datafile, \n",
    "                    checkpoint, modeltype, \n",
    "                    log_config, general_config, \n",
    "                    maskDir, incrementalPercent,\n",
    "                    saveImages, saveImageInterval, imageDir, imageLabel=\"\"):\n",
    "        super().__init__(datafile, log_config, general_config)\n",
    "       \n",
    "        self.output_dir = self.log_config.getOutDir() \n",
    "        self.genconfigs = snn.params(general_config)\n",
    "        self.checkpoint = checkpoint\n",
    "        self.modeltype = modeltype\n",
    "        self.maskDir = maskDir\n",
    "        self.incrementalPercent = incrementalPercent\n",
    "        self.saveImages = True\n",
    "        self.saveImageInterval = saveImageInterval\n",
    "        self.imageDir = '/scratch/mclerico/.'\n",
    "        self.imageLabel = imageLabel\n",
    "\n",
    "        if(datasetType == \"EVIMO\"):\n",
    "            #database = base.EVIMODatasetBase(datafile, self.genconfigs, self.maskDir, crop, maxBackgroundRatio, incrementalPercent)\n",
    "            database = EVIMODataset(datafile,100, False)\n",
    "            print(\"EVIMO used\")\n",
    "        elif(datasetType == \"MOD\"):\n",
    "            #database = base.MODDatasetBase(datafile, self.genconfigs, self.maskDir, crop, maxBackgroundRatio, incrementalPercent)\n",
    "            database = MODDataset(datafile + 'room1obj1-001.hdf5', datafile+'seq_room1_obj1/masks/', datafile+'seq_room1_obj1_neuroscience.h5', 100)\n",
    "            print(\"MOD used\")\n",
    "        else:\n",
    "            raise Exception(\"Only EVIMO or MOD datasets with hdf5 format generated by preprocessing scripts handled with this code.\")\n",
    "\n",
    "        num_workers = self.genconfigs['hardware']['readerThreads']\n",
    "        batch_size = self.genconfigs['batchsize']\n",
    "        self.loader = torch.utils.data.DataLoader(database, batch_size=8, shuffle=False, num_workers=8, collate_fn=my_collate, drop_last = False)\n",
    "        self.tb_writer = SummaryWriter(self.output_dir)    \n",
    "\n",
    "    def test(self):\n",
    "        #self._loadNetFromCheckpoint(self.checkpoint, self.modeltype)\n",
    "        self.net = self.net.eval()\n",
    "\n",
    "        total_IOU = 0\n",
    "        total_input_IOU = 0\n",
    "        \n",
    "        scalar_i = 0\n",
    "        tot_frames = 0\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        if self.saveImages and not os.path.exists(self.imageDir):\n",
    "                os.mkdir(self.imageDir)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.loader):\n",
    "                if (data == None):\n",
    "                    continue\n",
    "                data = moveToGPUDevice(data, device, None)\n",
    "                oms_spikes_input = data['oms_spike_tensor']\n",
    "                oms_spikes_masked = data['oms_mask']\n",
    "                spikes_input = data['dvs_spike_tensor']\n",
    "\n",
    "                ioucriterion = snn.loss(self.genconfigs).to(self.device) \n",
    "\n",
    "                #calculate metrics\n",
    "                tot_frames += spikes_input.shape[0]\n",
    "\n",
    "                #spike_pred_2D = torch.sum(spike_pred, axis = (1,4))\n",
    "                oms_mask_2D = torch.sum(oms_spikes_masked, axis = (1,4))\n",
    "                boxes_gt =masks_to_boxes(oms_mask_2D)\n",
    "\n",
    "                #oms_mask_2D[oms_mask_2D>1] = 1\n",
    "                oms_spike_2D = torch.sum(oms_spikes_input, axis=(1,4))\n",
    "                boxes_pred =  masks_to_boxes(oms_spike_2D)\n",
    "\n",
    "                for i in range(oms_mask_2D.shape[0]):\n",
    "                    print(detection_rate(boxes_gt[i], boxes_pred[i]))\n",
    "                #print(\"PRED IOU\", iou)\n",
    "                input_iou = ioucriterion.getIOU(oms_spike_2D, oms_mask_2D)\n",
    "                print(\"OMS INPUT IoU\", input_iou)\n",
    "                print(\"-------------------------------------------------\")\n",
    "\n",
    "                total_input_IOU += input_iou*spikes_input.shape[0]\n",
    "                scalar_i += 1\n",
    "                #self.tb_writer.add_scalar('iou', iou.item(), scalar_i)\n",
    "                \"\"\" \n",
    "                if self.saveImages and (i)%self.saveImageInterval== 0:\n",
    "                    spikes_maskednp = np.array(oms_spikes_masked.detach().cpu())\n",
    "                    #spikesPred_np = np.array(spikepred.detach().cpu())\n",
    "                    spikesInput_np = np.array(oms_spikes_input.detach().cpu())\n",
    "\n",
    "                    #print(\"save to: \", self.output_dir)\n",
    "\n",
    "                    for batch in range(0,spikes_input.shape[0]):\n",
    "                        curr_num = i+batch            \n",
    "                        #im = Image.fromarray(np.uint8(np.sum(spikesPred_np[batch,:,:,:,:], axis=(0,3))*255))\n",
    "                        #im.save(os.path.join(self.imageDir,\"_pred_epoch{}\".format(batch) + self.imageLabel + \".jpg\"))\n",
    "\n",
    "                        im2 = Image.fromarray(np.uint8( 255 - np.sum(spikes_maskednp[batch,:,:,:,:], axis=(0,3))*255))\n",
    "                        im2.save(os.path.join(self.imageDir,\"_ideal_epoch{}\".format(curr_num) + self.imageLabel + \".jpg\"))\n",
    "\n",
    "                        im3 = Image.fromarray(np.uint8(255- np.sum(spikesInput_np[batch,:,:,:,:], axis=(0,3))*255))\n",
    "                        im3.save(os.path.join(self.imageDir,\"_input_epoch{}\".format(curr_num) + self.imageLabel + \".jpg\"))\n",
    "                \"\"\"\n",
    "\n",
    "        #print(\"save to: \", self.output_dir)\n",
    "\n",
    "        if self.saveImages:\n",
    "            print(\"saving images to\", os.getcwd(), self.imageDir)\n",
    "\n",
    "        print(\"mean OMS IoU for {} batches of frames\".format(tot_frames), total_input_IOU/tot_frames)\n",
    "        #print(\"mean DVS IoU for {} batches of frames\".format(tot_frames), total_IOU/tot_frames)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
