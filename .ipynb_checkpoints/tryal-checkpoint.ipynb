{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b8296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datasets.evimo_dataset import EVIMODataset\n",
    "import dataloader.base as base\n",
    "\n",
    "from utils.masks_to_boxes import masks_to_boxes, detection_rate\n",
    "from utils.gpu import moveToGPUDevice\n",
    "from utils.rbase import RBase\n",
    "\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import torch.nn as nn \n",
    "from PIL import Image\n",
    "import slayerpytorch as snn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51999274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runner class was taken and modified from https://github.com/prgumd/SpikeMS/blob/main/runner.py\n",
    "\"\"\"\n",
    "def my_collate(batch):\n",
    "    batch = list(filter (lambda x:x is not None, batch))\n",
    "    if not batch:\n",
    "        return None\n",
    "\n",
    "    return default_collate(batch)\n",
    "\n",
    "class Runner(RBase):\n",
    "\n",
    "    def __init__(self, crop, maxBackgroundRatio, datasetType, datafile, \n",
    "                    checkpoint, modeltype, \n",
    "                    log_config, general_config, \n",
    "                    maskDir, incrementalPercent,\n",
    "                    saveImages, saveImageInterval, imageDir, imageLabel=\"\"):\n",
    "        super().__init__(datafile, log_config, general_config)\n",
    "       \n",
    "        self.output_dir = self.log_config.getOutDir() \n",
    "        self.genconfigs = snn.params(general_config)\n",
    "        self.checkpoint = checkpoint\n",
    "        self.modeltype = modeltype\n",
    "        self.maskDir = maskDir\n",
    "        self.incrementalPercent = incrementalPercent\n",
    "        self.saveImages = True\n",
    "        self.saveImageInterval = saveImageInterval\n",
    "        # TODO\n",
    "        # Change to the path where the OMS and groundtruth masks .png files are\n",
    "        oms_datadir = \"/scratch/mclerico/dataset/eval_96\"\n",
    "        masks_datadir = \"/scratch/mclerico/dataset/eval\"\n",
    "        #self.imageDir = '/scratch/mclerico/.'\n",
    "        self.imageLabel = imageLabel\n",
    "\n",
    "        if(datasetType == \"EVIMO\"):\n",
    "            #database = base.EVIMODatasetBase(datafile, self.genconfigs, self.maskDir, crop, maxBackgroundRatio, incrementalPercent)\n",
    "            database = EVIMODataset(datafile,oms_datadir, masks_datadir, 100, False)\n",
    "            print(\"EVIMO used\")\n",
    "        elif(datasetType == \"MOD\"):\n",
    "            #database = base.MODDatasetBase(datafile, self.genconfigs, self.maskDir, crop, maxBackgroundRatio, incrementalPercent)\n",
    "            database = MODDataset(datafile + 'room1obj1-001.hdf5', datafile+'seq_room1_obj1/masks/', datafile+'seq_room1_obj1_neuroscience.h5', 100)\n",
    "            print(\"MOD used\")\n",
    "        else:\n",
    "            raise Exception(\"Only EVIMO or MOD datasets with hdf5 format generated by preprocessing scripts handled with this code.\")\n",
    "\n",
    "        num_workers = self.genconfigs['hardware']['readerThreads']\n",
    "        batch_size = self.genconfigs['batchsize']\n",
    "        self.loader = torch.utils.data.DataLoader(database, batch_size=8, shuffle=False, num_workers=8, collate_fn=my_collate, drop_last = False)\n",
    "        self.tb_writer = SummaryWriter(self.output_dir)    \n",
    "\n",
    "    def test(self):\n",
    "        #self._loadNetFromCheckpoint(self.checkpoint, self.modeltype)\n",
    "        self.net = self.net.eval()\n",
    "\n",
    "        total_IOU = 0\n",
    "        total_input_IOU = 0\n",
    "        \n",
    "        scalar_i = 0\n",
    "        tot_frames = 0\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        if self.saveImages and not os.path.exists(self.imageDir):\n",
    "                os.mkdir(self.imageDir)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.loader):\n",
    "                if (data == None):\n",
    "                    continue\n",
    "                data = moveToGPUDevice(data, device, None)\n",
    "                oms_spikes_input = data['oms_spike_tensor']\n",
    "                oms_spikes_masked = data['oms_mask']\n",
    "                spikes_input = data['dvs_spike_tensor']\n",
    "\n",
    "                ioucriterion = snn.loss(self.genconfigs).to(self.device) \n",
    "\n",
    "                #calculate metrics\n",
    "                tot_frames += spikes_input.shape[0]\n",
    "\n",
    "                #spike_pred_2D = torch.sum(spike_pred, axis = (1,4))\n",
    "                oms_mask_2D = torch.sum(oms_spikes_masked, axis = (1,4))\n",
    "                boxes_gt =masks_to_boxes(oms_mask_2D)\n",
    "\n",
    "                #oms_mask_2D[oms_mask_2D>1] = 1\n",
    "                oms_spike_2D = torch.sum(oms_spikes_input, axis=(1,4))\n",
    "                boxes_pred =  masks_to_boxes(oms_spike_2D)\n",
    "\n",
    "                for i in range(oms_mask_2D.shape[0]):\n",
    "                    print(detection_rate(boxes_gt[i], boxes_pred[i]))\n",
    "                #print(\"PRED IOU\", iou)\n",
    "                input_iou = ioucriterion.getIOU(oms_spike_2D, oms_mask_2D)\n",
    "                print(\"OMS INPUT IoU\", input_iou)\n",
    "                print(\"-------------------------------------------------\")\n",
    "\n",
    "                total_input_IOU += input_iou*spikes_input.shape[0]\n",
    "                scalar_i += 1\n",
    "                #self.tb_writer.add_scalar('iou', iou.item(), scalar_i)\n",
    "                \"\"\" \n",
    "                if self.saveImages and (i)%self.saveImageInterval== 0:\n",
    "                    spikes_maskednp = np.array(oms_spikes_masked.detach().cpu())\n",
    "                    #spikesPred_np = np.array(spikepred.detach().cpu())\n",
    "                    spikesInput_np = np.array(oms_spikes_input.detach().cpu())\n",
    "\n",
    "                    #print(\"save to: \", self.output_dir)\n",
    "\n",
    "                    for batch in range(0,spikes_input.shape[0]):\n",
    "                        curr_num = i+batch            \n",
    "                        #im = Image.fromarray(np.uint8(np.sum(spikesPred_np[batch,:,:,:,:], axis=(0,3))*255))\n",
    "                        #im.save(os.path.join(self.imageDir,\"_pred_epoch{}\".format(batch) + self.imageLabel + \".jpg\"))\n",
    "\n",
    "                        im2 = Image.fromarray(np.uint8( 255 - np.sum(spikes_maskednp[batch,:,:,:,:], axis=(0,3))*255))\n",
    "                        im2.save(os.path.join(self.imageDir,\"_ideal_epoch{}\".format(curr_num) + self.imageLabel + \".jpg\"))\n",
    "\n",
    "                        im3 = Image.fromarray(np.uint8(255- np.sum(spikesInput_np[batch,:,:,:,:], axis=(0,3))*255))\n",
    "                        im3.save(os.path.join(self.imageDir,\"_input_epoch{}\".format(curr_num) + self.imageLabel + \".jpg\"))\n",
    "                \"\"\"\n",
    "\n",
    "        #print(\"save to: \", self.output_dir)\n",
    "\n",
    "        if self.saveImages:\n",
    "            print(\"saving images to\", os.getcwd(), self.imageDir)\n",
    "\n",
    "        print(\"mean OMS IoU for {} batches of frames\".format(tot_frames), total_input_IOU/tot_frames)\n",
    "        #print(\"mean DVS IoU for {} batches of frames\".format(tot_frames), total_IOU/tot_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1af12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mavi/eecv_suplementary/logs/20240312-185802\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/scratch/mclerico/dataset/eval_96/wall/seq_01_frames/seq_01_frames_neuroscience.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m datafile\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwall/seq_01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m config_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_config.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxBackgroundRatio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasetType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatafile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatafile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#no model for checkpoint\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodeltype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# no model type required\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlog_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgeneral_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmaskDir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mincrementalPercent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[43msaveImages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[43msaveImageInterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimageDir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mstarting to run \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m.\u001b[39msegDatasetType, args\u001b[38;5;241m.\u001b[39mmodeltype))\n\u001b[1;32m     27\u001b[0m runner\u001b[38;5;241m.\u001b[39mtest()\n",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m, in \u001b[0;36mRunner.__init__\u001b[0;34m(self, crop, maxBackgroundRatio, datasetType, datafile, checkpoint, modeltype, log_config, general_config, maskDir, incrementalPercent, saveImages, saveImageInterval, imageDir, imageLabel)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimageLabel \u001b[38;5;241m=\u001b[39m imageLabel\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(datasetType \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVIMO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#database = base.EVIMODatasetBase(datafile, self.genconfigs, self.maskDir, crop, maxBackgroundRatio, incrementalPercent)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     database \u001b[38;5;241m=\u001b[39m \u001b[43mEVIMODataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatafile\u001b[49m\u001b[43m,\u001b[49m\u001b[43moms_datadir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks_datadir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVIMO used\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(datasetType \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOD\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m#database = base.MODDatasetBase(datafile, self.genconfigs, self.maskDir, crop, maxBackgroundRatio, incrementalPercent)\u001b[39;00m\n",
      "File \u001b[0;32m~/eecv_suplementary/datasets/evimo_dataset.py:34\u001b[0m, in \u001b[0;36mEVIMODataset.__init__\u001b[0;34m(self, data_dir, oms_dir, masks_dir, num_steps, dvs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moms_file \u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moms_file ,  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moms_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moms_file\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_neuroscience.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moms_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moms_frames\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.9/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.9/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/scratch/mclerico/dataset/eval_96/wall/seq_01_frames/seq_01_frames_neuroscience.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "from config.utils import getTestConfigs\n",
    "\n",
    "#sets up logging configs and dirs\n",
    "configs = getTestConfigs(os.path.join(os.getcwd(), 'logs'), os.path.join(os.getcwd(), 'general_config.yaml'))\n",
    "\n",
    "# TODO\n",
    "# Either 'EVIMO' or 'MOD' to test each dataset\n",
    "dataset_type = \"EVIMO\"\n",
    "# TODO\n",
    "# Change to test with different validation sequences\n",
    "datafile= \"wall/seq_01\"\n",
    "config_file = os.path.join(os.getcwd(), 'general_config.yaml')\n",
    "runner = Runner(crop=False, maxBackgroundRatio=1.5, datasetType=dataset_type, datafile=datafile,\n",
    "                checkpoint='/', #no model for checkpoint\n",
    "                modeltype='', # no model type required\n",
    "                log_config=configs['log'],\n",
    "                general_config=config_file,\n",
    "                maskDir='', \n",
    "                incrementalPercent = 1,\n",
    "                saveImages= False, \n",
    "                saveImageInterval=1, \n",
    "                imageDir=\"\")\n",
    "print(\"\\nstarting to run {} {}\".format(args.segDatasetType, args.modeltype))\n",
    "runner.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
